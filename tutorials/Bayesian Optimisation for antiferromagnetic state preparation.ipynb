{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal control for an antiferromagnetic state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The following notebook gives an overview of the application of an optimal control method using Pulser. The announced objective is to achieve the preparation of the well-known antiferromagnetic state - see tutorial _Preparing an AF state in the Ising model_ - on a squared configuration of neutral atoms using optimised pulses smoother than the usual ramps. We define by AF state an equal mixture of the two \"checkerboard\" spin states. \n",
    "\n",
    "<center>\n",
    "<img src=\"files/AFstate_1D.png\" alt=\"AFgrid\" width=\"500\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing some basic modules as well as an optimisation function based on Gaussian processes `gp_minimize` and an interpolation function `PchipInterpolator`. In addition, this notebook uses the `scikit-optimize` packade, which has to be installed beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import qutip\n",
    "import time\n",
    "\n",
    "from pulser import Pulse, Sequence, Register, Simulation\n",
    "from pulser.waveforms import ConstantWaveform, RampWaveform, CustomWaveform\n",
    "from pulser.devices import Chadoq2\n",
    "\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from skopt import gp_minimize\n",
    "from skopt import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. System and Parameters\n",
    "The parameters which will bound the parameter space during the optimisation are chosen as in _Preparing an AF state in the Ising model_. A squared register of $4\\times 4$ atoms with a central $2\\times 2$ square of atoms missing is created. It is equivalent to a chain of $12$ atoms but avoids edge effects which alter the system dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters in MHz and ns\n",
    "U = 2 * np.pi * 5.0\n",
    "\n",
    "Omega_max = 0.5 * U \n",
    "\n",
    "delta_0 = -1.0 * U \n",
    "delta_f = 1.0 * U \n",
    "\n",
    "R_interatomic = Chadoq2.rydberg_blockade_radius(Omega_max) / 1.2\n",
    "print(f'Interatomic Radius is: {R_interatomic}µm.')\n",
    "\n",
    "N_side = 4\n",
    "coords = [R_interatomic * np.r_[x,0] for x in range(N_side-1)] + [R_interatomic * np.r_[N_side-1,y] for y in range(N_side-1)] \\\n",
    "    + [R_interatomic * np.r_[N_side-1-x,N_side-1] for x in range(N_side-1)] + [R_interatomic * np.r_[0,N_side-1-y] for y in range(N_side-1)]\n",
    "#coords = np.array([(x,y) for x in range(N_side) for y in range(N_side) if x in {0, N_side-1} or y in {0, N_side-1}]) * R_interatomic\n",
    "reg = Register.from_coordinates(coords, prefix='q')\n",
    "N=len(reg._ids)\n",
    "\n",
    "reg.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of simulation (in ns)\n",
    "T= 1500\n",
    "time_domain=np.linspace(0, T, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A channel is declared on the Chadoq2 device in order to check the feasibility of the pulses. If the extreme values of $\\Omega_{max}$, $\\delta_0$ and $\\delta_f$ exceed the thresholds proposed by Chadoq2, a restriction is required. The best case scenario is to take extreme values which coincide with those of the device, especially for $\\delta_0$ and $\\delta_f$ since they parameterise the adiabatic evolution of the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequence(reg, Chadoq2)\n",
    "seq.declare_channel('ising', 'rydberg_global')\n",
    "\n",
    "Omega_max=min([seq.declared_channels['ising'].max_amp, Omega_max])\n",
    "delta_0=np.sign(delta_0)*min([seq.declared_channels['ising'].max_abs_detuning, abs(delta_0)])\n",
    "delta_f=np.sign(delta_f)*min([seq.declared_channels['ising'].max_abs_detuning, abs(delta_f)])\n",
    "print(Omega_max/U,np.round(delta_0/U,2),delta_f/U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolated pulses\n",
    "The parameters fed to the optimisation algorithm must uniquely define $\\Omega$ and $\\delta$. Interpolated pulses, once the interpolation method has been set, can be fully described by $2m$ parameters, which are $\\{\\Omega(t_i),\\delta(t_i), i\\in[1,m]\\}$ with $t_i=T\\times i/(m+1)$. The larger $m$ is, the more complex the pulse behaviour could be but also the more resources are needed since the parameters space is expanding. Here, the interpolation is done with monotonic cubic splines using `PchipInterpolator`. \n",
    "\n",
    "<center>\n",
    "<img src=\"files/interpolated_pulses.png\" alt=\"Interpolated pulses\" width=\"800\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a random instance of interpolated pulse using Pulser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the parameter space\n",
    "m=3\n",
    "\n",
    "# Random instance of the parameter space\n",
    "para = np.r_[np.random.uniform(0,Omega_max,m),np.random.uniform(delta_0,delta_f,m)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an interpolation function which takes as argument a set of parameters and returns the interpolated pulses associated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_pulse_functions(Omega_pts,delta_pts,T):\n",
    "    m=len(Omega_pts)\n",
    "    ti=np.linspace(0,T,m)\n",
    "\n",
    "    cso = PchipInterpolator(ti,np.array(Omega_pts))\n",
    "    csd = PchipInterpolator(ti,np.array(delta_pts))\n",
    "    def Omega(t,*args):\n",
    "        return cso(t)\n",
    "    def delta(t,*args):\n",
    "        return csd(t)\n",
    "    return Omega,delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interp_pulse(para):\n",
    "    Omega_pts = np.r_[1e-9, para[:m], 1e-9]\n",
    "    delta_pts = np.r_[delta_0, para[m:], delta_f]\n",
    "    Omega_func, delta_func = interp_pulse_functions(Omega_pts, delta_pts,T)\n",
    "    Omega,delta=np.array(Omega_func(time_domain)),np.array(delta_func(time_domain))\n",
    "    P=Pulse(CustomWaveform(Omega),CustomWaveform(delta),0)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pulser, we define a Sequence on the Chadoq2 device and add the pulse to it. We can also visualize it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequence(reg, Chadoq2)\n",
    "seq.declare_channel('ising', 'rydberg_global')\n",
    "seq.add(create_interp_pulse(para),'ising')\n",
    "seq.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we simulate the effect of the sequence on the system we obtain the final state. With each set of parameters, a state of the system can be obtained.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simul = Simulation(seq)\n",
    "results = simul.run()\n",
    "final = results.states[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the first optimised pulse shapes are obtained, it is worth adding constraints to the interpolated shapes such as strict growth or derivative limitation to further guide the optimisation.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the optimisation algorithm to distinguish between these states and thus to browse the parameter space in search of an optimal shape of pulse, we need to assign a score to each set based on the state it allows us to reach. With the algorithm set to look for minimum, the AF state should have a score of 0 and all other states strictly positive score. The score will be defined based on the Néel structure factor $S_{Néel}$ defined in the tutorial _Preparing an AF state in the Ising model_ since we want an observable accessible by the processor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occupation(j, N):\n",
    "    up = qutip.basis(2,0)\n",
    "    prod = [qutip.qeye(2) for _ in range(N)]\n",
    "    prod[j] = up * up.dag()\n",
    "    return qutip.tensor(prod)\n",
    "\n",
    "def get_corr_pairs(k, N):\n",
    "    corr_pairs = [[i,(i+k)%N] for i in range(N)]\n",
    "    return corr_pairs\n",
    "\n",
    "def get_corr_function(k, N, state):\n",
    "    corr_pairs = get_corr_pairs(k, N)\n",
    "    operators = [occupation(j, N) for j in range(N)]\n",
    "    covariance = 0\n",
    "    for qi, qj in corr_pairs:\n",
    "        covariance += qutip.expect(operators[qi]*operators[qj], state)\n",
    "        covariance -= qutip.expect(operators[qi], state)*qutip.expect(operators[qj], state)\n",
    "    return covariance/len(corr_pairs)   \n",
    "\n",
    "def get_full_corr_function(reg, state):\n",
    "    N = len(reg.qubits)\n",
    "    correlation_function = {}\n",
    "    for k in range(-N//2, N//2+1):\n",
    "        correlation_function[k] = get_corr_function(k, N, state)\n",
    "    return correlation_function\n",
    "\n",
    "def get_neel_structure_factor(reg, state):\n",
    "    N = len(reg.qubits)\n",
    "    st_fac = 0\n",
    "    for k in range(-N//2, N//2+1):\n",
    "        kk = np.abs(k)\n",
    "        st_fac += 4 * (-1)**kk * get_corr_function(k, N, state)\n",
    "    return st_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one of Pulser's methods (`sample_final_state()` which belongs to the `SimulationResults` class) to sample from a state, wrapped in a function that displays those bitstrings above a certain threshold `min_p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulser.simresults import SimulationResults\n",
    "\n",
    "def proba_from_state(state, min_p=0.1):\n",
    "    study = SimulationResults([state], dim=2, size=N, basis_name='ground-rydberg')\n",
    "    sampling = study.sample_final_state(meas_basis='ground-rydberg', N_samples=1000)\n",
    "    return {k: f'{100*v/study.N_samples}%' for k,v in sampling.items() if v/study.N_samples > min_p}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create antiferromagnetic state as the superposition of the two checkerboard patterns:\n",
    "AF1 = qutip.tensor([qutip.basis(2,k%2) for k in range(N)])\n",
    "AF2 = qutip.tensor([qutip.basis(2,(k+1)%2) for k in range(N)])\n",
    "AF_state = (AF1 + AF2).unit()\n",
    "\n",
    "proba_from_state(AF_state, min_p=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S_{Néel}$ should reach its maximum for the previously defined AF state. The obtained value will allow to normalise the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.process_time()\n",
    "print('S_Neel(AF state) =', get_neel_structure_factor(reg, AF_state))\n",
    "t2=time.process_time()\n",
    "print('computed in', (t2-t1),'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score function thus wraps the previous functions and assigns a positive score to each instance of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(para):\n",
    "    seq = Sequence(reg, Chadoq2)\n",
    "    seq.declare_channel('ising', 'rydberg_global')\n",
    "    seq.add(create_interp_pulse(para),'ising')\n",
    "    \n",
    "    simul = Simulation(seq, sampling_rate=0.1)\n",
    "    results = simul.run()\n",
    "    \n",
    "    F = get_neel_structure_factor(reg, results.states[-1])/(2*(N-1))\n",
    "    return 1 - F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bayesian search \n",
    "Bayesian optimisation method has two keywords: model and decide. \n",
    "\n",
    "It consists of both a statistical model that simulates the unknown landscape function $F$ and a decision maker, the acquisition function $a$, which indicates where the next evaluation will be most likely to enhance optimization. Two distinct stages are carried out. In the supervised training, $F$ is surveyed according to an initial space-filling pattern. For small-sized spaces, the probing points $\\{x_i\\}$ can be formed into a discrete grid efficiently covering the entire search space. However, as the number of dimensions grows, it becomes less resource-consuming to conduct a uniformly random sample of $n$ points. \n",
    "\n",
    "A prior surrogate model of $F$ is established knowing only its values $\\{F(x_i)\\}_{1:n}$ at those $n$ points. Then, in the research part, each new point of a remaining budget $M-n$ is iteratively selected and used to update the model. That model provides a posterior probability distribution $f$, which approximates $F$ at every $x$. Using Gaussian processes for the modelling enables to get normally distributed $f(x)$, fully described by only two parameters: a mean and a variance.\n",
    "\n",
    "At each step of the algorithm, once the landscape  has been approximated over the search space, the acquisition function $a(x)$ can be updated, being completely determined by the  current distribution $f(x)$. $a$ relates to how desirable evaluating $F$ at $x$ is expected to be and its straightforward construction makes it a relatively inexpensive function to evaluate and thus to optimise. By focusing alternatively on exploration and exploitation, $a$ helps to locate the next optimal point to query, $x^{*}$. It might seem that we just traded one optimization problem for another, but the call cost of $a$ is usually derisory compared to the black box one. $F(x^{*})$ is then added to the known values of $F$ in order to refine the next model. \n",
    "\n",
    "After $M$ calls to $F$, the Bayesian algorithm outputs $x_{opt}$, the most \"useful\" point for the experiment, i.e. the supposed global minimum of $F$ or the point with the smallest mean in case of strong noise for instance. \n",
    "\n",
    "<center>\n",
    "<img src=\"files/diagram_baye_opt.png\" alt=\"baye_opt\" width=\"700\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Parameters\n",
    "We are probing the parameter space cons a $2m$-dimensional hyper-rectangle $[0,\\Omega_{max}]^m\\times[\\delta_0,\\delta_f]^m$ with $n_r$ training points and a total of $n_c$ probing points. The optimisation is achieved using `gp_minimize` from the module `scikit-optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bounds = [(0.0, seq.declared_channels['ising'].max_amp)] * m + [(delta_0, delta_f)] * m\n",
    "\n",
    "n_r = 40\n",
    "n_c = 120\n",
    "\n",
    "RESULT = gp_minimize(score, bounds, n_random_starts=n_r, n_calls=n_c, verbose=False,kappa=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the optimisation is well-designed, i.e. enough but not too many steps, we plot its performance in terms of the minimum score found after $n_{calls}$ to the score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_improv(RESULT):\n",
    "    score_vals = RESULT.func_vals\n",
    "    min = score_vals[0]\n",
    "    score_list=[]\n",
    "    for s in score_vals:\n",
    "        if s<min:\n",
    "            min=s\n",
    "            score_list.append(min)\n",
    "        else:\n",
    "            score_list.append(min)\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.semilogy(range(n_c), sort_improv(RESULT), 'r-')\n",
    "plt.xlabel(r'$n_{calls}$', fontsize=14)\n",
    "plt.ylabel(r'$Score reached$', fontsize=14)\n",
    "plt.legend(['1 run'],fontsize=12)\n",
    "plt.xlim(0,n_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Bayesian optimisation is a stochastic algorithm, its results may vary between different runs. A 5-run average convergence of the algorithm for the same parameters is shown below. The scores achieved after the total number of calls all remain within an appreciable range.\n",
    "\n",
    "<center>\n",
    "<img src=\"files/Average_convs.png\" alt=\"AFgrid\" width=\"700\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimised pulse\n",
    "An interpolated pulse is produced based on the optimised parameters RESULT.x and then added to a new sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequence(reg, Chadoq2)\n",
    "seq.declare_channel('ising', 'rydberg_global')\n",
    "P = create_interp_pulse(RESULT.x)\n",
    "seq.add(P,'ising')\n",
    "seq.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pulse sequence travels though the following path in the phase diagram of the system (the shaded area represents the antiferromagnetic phase):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = []\n",
    "omega = []\n",
    "for x in seq._schedule['ising']:\n",
    "    if isinstance(x.type,Pulse):\n",
    "        omega += list(x.type.amplitude.samples / U)\n",
    "        delta += list(x.type.detuning.samples / U)\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "ax.set_ylabel(r\"$\\hbar\\delta(t)/U$\", fontsize=14)\n",
    "ax.set_xlabel(r\"$\\hbar\\Omega(t)/U$\", fontsize=14)\n",
    "ax.set_xlim(0, Omega_max/U*1.1)\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "\n",
    "y = np.arange(0.0, 3, 0.01)\n",
    "x = 0.5 * (1 - 1.0 * (y - 1)**2)\n",
    "ax.fill_between(x, y, alpha=0.4)\n",
    "\n",
    "ax.plot(omega,delta, 'red', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simul = Simulation(seq)\n",
    "results = simul.run()\n",
    "final=results.states[-1]\n",
    "print('final =', proba_from_state(final, min_p=0.05))\n",
    "\n",
    "s_neel = np.round(get_neel_structure_factor(reg, final),3)\n",
    "print(f'S_Neel (final) = {s_neel}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value should be compared to its equivalent in the tutorial _Preparing an AF state in the Ising model_. For a ramp pulse with the same parameters and for a square configuration, the structural factor is around $2.75$ for a maximum of $24$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip parameter. Only 1 out of 10 pts are kept to enhance the speed.\n",
    "a = 10\n",
    "time_domain_reduced = [a*i for i in range(len(results.states)//a)]\n",
    "S_Neel_states=[get_neel_structure_factor(reg, results.states[a*i]) for i in range(len(results.states)//a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_domain_reduced,S_Neel_states)\n",
    "plt.xlabel('Time (ns)',fontsize=12)\n",
    "plt.ylabel(r'$S_{Néel}$',fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation properties\n",
    "To identify any AF properties of the final state, it is also possible to examine its correlation function $g^{(2)}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_function = get_full_corr_function(reg, final)\n",
    "\n",
    "A = np.reshape(list(correlation_function.values()), (1, N+1))\n",
    "A[0,N//2] = None\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(A, cmap='coolwarm')\n",
    "plt.xlabel('k',fontsize=12)\n",
    "plt.xticks(range(A.shape[1]), ['{}'.format(i) for i in range(-N//2 , N//2+1)])\n",
    "plt.title(r'$g^{(2)}(k)$ after simulation', fontsize=14)\n",
    "plt.yticks([])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the correlation function would follow an exponential decay (modulo finite-size effects), which is best observed at larger system sizes. A perfect AF state should be as decorrelated as possible, i.e. with a correlation length as great as possible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
